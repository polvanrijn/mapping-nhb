{"Burkhardt2005": false, "EngbergHansen1996": false, "Morrison2007": false, "Nwe2003": false, "Hozjan2002": false, "YouChen1997": false, "Schuller2005": false, "Schuller2002": false, "Kim2007": {"names": "Kim, EH; Hyun, KH; Kim, SH; Kwak, YK", "full_names": "Kim, Eun Ho; Hyun, Kyung Hak; Kim, Soo Hyun; Kwak, Yoon Keun", "title": "Speech emotion recognition using eigen-FFT in clean and noisy environments", "journal": "2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3", "language": "English", "publication_type": "Proceedings Paper", "author_keywords": NaN, "keywords_plus": NaN, "abstract": "The ability to recognize human emotion is one of the basic techniques of human-robot interaction especially on emotional interaction points of view. Hence the purpose of this paper is to describe the realization of the recognition of emotion from a voice. Especially, this paper describes a speech emotion recognition technique using eigen-FFT. In the field of speech emotion recognition, recognition rate is important not only in clean but also in noisy environments. Hence, we constructed voice noise (or babble noise) data and performed recognition tests both in clean and noisy environments using the eigen-FTT. From the experiments, we achieved accuracy of 90.1+/-7.7% for four emotions at a 95% confidence interval and compared eigen-FFT with LPC, MFCC, and pitch in the clean environment. In the case of the noisy environments, eigen-FFT displayed superior performance over LPC, MFCC, and pitch.", "affiliation": "[Kim, Eun Ho; Hyun, Kyung Hak; Kim, Soo Hyun; Kwak, Yoon Keun] Korea Adv Inst Sci & Technol, Dept Mech Engn, Sch Mech Aerosp & Syst Engn, Taejon 305701, South Korea", "author_information": "Kim, EH (reprint author), Korea Adv Inst Sci & Technol, Dept Mech Engn, Sch Mech Aerosp & Syst Engn, Taejon 305701, South Korea.", "email": "kimeunho@kaist.ac.kr; cromno9@kaist.ac.kr; soohyun@kaist.ac.kr; ykkwak@kaist.ac.kr", "citation_count_WOS": 23, "wos_usage_count_180": 0, "wos_usage_count_2013": 0, "journal_abbr": NaN, "month_day": NaN, "year": 2007, "volume": NaN, "issue": NaN, "category1": "Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Robotics", "category2": "Computer Science; Engineering; Robotics", "DOI": NaN}, "Zhou2006": {"names": "Zhou, J; Wang, GY; Yang, Y; Chen, PJ", "full_names": "Zhou, Jian; Wang, Guoyin; Yang, Yong; Chen, Peijun", "title": "Speech emotion recognition based on rough set and SVM", "journal": "PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2", "language": "English", "publication_type": "Proceedings Paper", "author_keywords": "speech emotion recognition; rough set; feature selection; SVM", "keywords_plus": NaN, "abstract": "Speech emotion recognition is becoming more and more important in such computer application fields as health care, children education, etc. There are a few works have been done on speech emotion recognition using such methods as ANN, SVM, etc in the last years. Traditional feature selection method used in speech emotion recognition is computationally too expensive to determine an optimum or suboptimum feature subset. In this paper, a novel approach based on rough set theory and SVM for speech emotion recognition is proposed. The experiment results show this approach can reduce the calculation cost while keeping high recognition rate.", "affiliation": "[Zhou, Jian; Chen, Peijun] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China; [Zhou, Jian; Wang, Guoyin; Yang, Yong; Chen, Peijun] Chongqing Univ Posts & Telecommun, Inst Comp Sci & Technol, Chongqing 400065, Peoples R China", "author_information": "Zhou, J (reprint author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.", "email": "swjtuzhoujian@163.com", "citation_count_WOS": 20, "wos_usage_count_180": 1, "wos_usage_count_2013": 2, "journal_abbr": NaN, "month_day": NaN, "year": 2006, "volume": NaN, "issue": NaN, "category1": "Computer Science, Artificial Intelligence; Computer Science, Software Engineering", "category2": "Computer Science", "DOI": NaN}, "Hu2007": {"names": "Hu, H; Xu, MX; Wu, W", "full_names": "Hu, Hao; Xu, Ming-Xing; Wu, Wei", "title": "GMM supervector based SVM with spectral features for speech emotion recognition", "journal": "2007 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PTS 1-3", "language": "English", "publication_type": "Proceedings Paper", "author_keywords": "speech emotion recognition; SVM; GMM supervector; spectral features", "keywords_plus": NaN, "abstract": "Speech emotion recognition is a challenging yet important speech technology. In this paper, the GMM supervector based SVM is applied to this field with spectral features. A GMM is trained for each emotional utterance, and the corresponding GMM supervector is used as the input feature for SVM. Experimental results on an emotional speech database demonstrate that the GMM supervector based SVM outperforms standard GMM on speech emotion recognition.", "affiliation": "[Hu, Hao; Xu, Ming-Xing; Wu, Wei] Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Ctr Speech Technol, Beijing 100084, Peoples R China", "author_information": "Hu, H (reprint author), Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Ctr Speech Technol, Beijing 100084, Peoples R China.", "email": "huhao@cst.cs.tsinghua.edu.cn; xumx@tsinghua.edu.cn; wuwei@cst.cs.tsinghua.edu.cn", "citation_count_WOS": 14, "wos_usage_count_180": 1, "wos_usage_count_2013": 4, "journal_abbr": NaN, "month_day": NaN, "year": 2007, "volume": NaN, "issue": NaN, "category1": "Acoustics; Engineering, Electrical & Electronic; Telecommunications", "category2": "Acoustics; Engineering; Telecommunications", "DOI": NaN}, "Amir2000": false}